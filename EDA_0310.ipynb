{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from preprocess import *\n",
    "from visualize import *\n",
    "from classification import *\n",
    "from Sampling import *\n",
    "from feature_engineering import *\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when 1st execution - Comment after\n",
    "# base_dir = Path('./RMHD/raw data')  # Current dir\n",
    "# monthly_df = []\n",
    "# years = ['2019', '2020', '2021', '2022']\n",
    "\n",
    "# for year in years:\n",
    "#     year_dir = base_dir / year\n",
    "        \n",
    "#     print(f\"Processing year: {year}\")\n",
    "#     # month folder in year\n",
    "#     for subdir_path in year_dir.iterdir():\n",
    "#         if not subdir_path.is_dir():\n",
    "#             continue\n",
    "            \n",
    "#         print(f\"  Processing subdirectory: {subdir_path.name}\")\n",
    "#         # Find all CSV files in the subdir\n",
    "#         csv_files = list(subdir_path.glob('*.csv'))\n",
    "        \n",
    "#         for csv_file in csv_files:\n",
    "#             print(f\"    Reading file: {csv_file.name}\")\n",
    "#             df = pd.read_csv(csv_file)\n",
    "#             df = df.drop(df.columns[0], axis=1) # drop first col\n",
    "#             monthly_df.append(df)\n",
    "\n",
    "# # Concat all dataframes\n",
    "# if monthly_df:\n",
    "#     df = pd.concat(monthly_df, ignore_index=True)\n",
    "# else:\n",
    "#     print(\"No CSV files found or all files were empty.\")\n",
    "\n",
    "# df.to_csv('data_samples/RMHD_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_samples/RMHD_raw.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['subreddit'].value_counts())\n",
    "\n",
    "#countplot(\"subreddit distribution\", df, \"subreddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = limit_subreddits(df) # Take top 5 subreddit records\n",
    "df_sampled = sample_mental_health_data(df = df, output_file = 'data_samples/RMHD_Sampled.csv') # Undersample\n",
    "print(df_sampled['subreddit'].value_counts())\n",
    "df_processed = preprocess(df_sampled) # Pre process (drop na, datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 8))\n",
    "\n",
    "# sns.barplot(df['timestamp'].dt.to_period('M').value_counts().sort_index())\n",
    "\n",
    "# # Customize appearance\n",
    "# plt.title('Monthly Post Frequency', fontsize=16)\n",
    "# plt.xlabel('Month', fontsize=14)\n",
    "# plt.ylabel('Number of Posts', fontsize=14)\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['title_processed'] = df_processed['title'].progress_apply(text_process)\n",
    "df_processed['selftext_processed'] = df_processed['selftext'].progress_apply(text_process)\n",
    "df.to_csv(\"data_samples/RMHD_TextProcessed.csv\", index = False)\n",
    "\n",
    "# Display example results\n",
    "print(\"Original Title:\")\n",
    "print(df_processed['title'].iloc[0])\n",
    "print(\"\\nProcessed Title:\")\n",
    "print(df_processed['title_processed'].iloc[0])\n",
    "print(\"\\nOriginal Selftext:\")\n",
    "print(df_processed['selftext'].iloc[0])\n",
    "print(\"\\nProcessed Selftext:\")\n",
    "print(df_processed['selftext_processed'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = df_sampled['subreddit'].value_counts().head().index\n",
    "\n",
    "# title\n",
    "for subreddit in subreddits:\n",
    "    text = ' '.join(df_sampled[df_sampled['subreddit'] == subreddit]['title_processed'])\n",
    "    plot_wordcloud(text, f\"{subreddit} Title Word Cloud\")\n",
    "\n",
    "# selftext\n",
    "for subreddit in subreddits:\n",
    "    text = ' '.join(df_sampled[df_sampled['subreddit'] == subreddit]['selftext_processed'])\n",
    "    plot_wordcloud(text, f\"{subreddit} SelfText Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled['text'] = df_sampled['title_processed'] + \" \" + df_sampled['selftext_processed']\n",
    "lda_topics, lda, count_vectorizer = extract_lda_features(df_sampled['text'])\n",
    "\n",
    "df_sampled['dominant_topic'] = np.argmax(lda_topics, axis=1)\n",
    "topic_class_matrix = df_sampled.groupby(['dominant_topic', 'subreddit']).size().unstack().fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(topic_class_matrix, annot=True, fmt='.0f', cmap='YlGnBu')\n",
    "plt.title(\"Topic-Class Distribution Heatmap (LDA)\")\n",
    "plt.xlabel(\"Subreddit\")\n",
    "plt.ylabel(\"Dominant Topic\")\n",
    "plt.savefig('Topic-Class_Distribution_Heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    top_words_idx = topic.argsort()[:-21:-1]  # get top 10 words\n",
    "    top_words = [feature_names[idx] for idx in top_words_idx]\n",
    "    print(f\"Topic #{i+1}:\")\n",
    "    print(\", \".join(top_words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic #1: Keywords such as “dont”, “want”, “life”, “feel”, “anymore”, “fucking” suggest strong mood swings that may involve despair, helplessness, or dissatisfaction with life, and may even involve depression or suicidal thoughts.\n",
    "\n",
    "Topic #2: Keywords such as “feel”, “really”, “want”, “time”, “thing” suggest that the topic may be related to inner feelings and confusion in life, and may involve self-doubt or uncertainty.\n",
    "\n",
    "Topic #3: Keywords such as “friend”, “year”, “school”, “job” suggest that this topic may be related to life experiences such as changes in upbringing, education, work, and friendships.\n",
    "\n",
    "Topic #4: Keywords such as “people”, “like”, “friend”, “make” suggest that this topic may be related to social relationships, interpersonal interactions, and perceptions of other people or society, and may be associated with feelings of loneliness or social anxiety.\n",
    "\n",
    "Topic #5: Keywords such as “anxiety”, “attack”, “help”, “day”, “time” explicitly point to symptoms of anxiety and may relate to panic attacks, help-seeking, and mental health issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
